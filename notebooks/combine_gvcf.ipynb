{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e74a52-2cad-4ae1-a91a-7914561c4d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/eriurn/submit/python37_intel/lib/python3.7/site-packages/pyspark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 02:05:47 WARN  Hail:43 - This Hail JAR was compiled for Spark 3.1.1, running with Spark 3.1.2.\n",
      "  Compatibility is not guaranteed.\n",
      "2022-02-07 02:05:49 WARN  Client:69 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 3.1.2\n",
      "SparkUI available at http://dice01-mlx.mlx:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.68-13190f0b6103\n",
      "LOGGING: writing to /home/eriurn/Hail-joint-caller/notebooks/hail-20220207-0205-0.2.68-13190f0b6103.log\n"
     ]
    }
   ],
   "source": [
    "import hail as hl\n",
    "hl.init(app_name=\"run_combiner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d934465c-1f41-4f5d-8cc4-95e3b1c9bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variables\n",
    "output_file = \"file:///directflow/ClinicalGenomicsPipeline/dev/2021-02-04-PIPELINE-1885-All-Hail/EricData/100_samples_GRCh37_2.mt\" # output destination\n",
    "temp_bucket = \"file:///directflow/ClinicalGenomicsPipeline/dev/2021-02-04-PIPELINE-1885-All-Hail/EricData/\"                       # directory for intermediate files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92c9e55-0552-47e6-a739-7fb775525319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_name_map is a file with one GVCF path per line\n",
    "path_to_input_list = 'file:///directflow/ClinicalGenomicsPipeline/dev/2021-02-04-PIPELINE-1885-All-Hail/EricData/sample_name_map'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429d4899-e9bf-4ba1-966d-ad138951174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "with hl.hadoop_open(path_to_input_list, 'r') as f:\n",
    "    for line in f:\n",
    "        inputs.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7084a974-5e95-40ad-a8d9-1e0a16cf058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c358ad-c4b1-4b0b-84de-544f47582de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 02:29:39 Hail: INFO: Using 2592 intervals with default whole-genome size 1200000 as partitioning for GVCF import\n",
      "2022-02-07 02:29:39 Hail: INFO: GVCF combiner plan:\n",
      "    Branch factor: 100\n",
      "    Batch size: 100\n",
      "    Combining 100 input files in 1 phases with 1 total jobs.\n",
      "        Phase 1: 1 job corresponding to 1 final output file.\n",
      "\n",
      "2022-02-07 02:29:39 Hail: INFO: Starting phase 1/1, merging 100 input GVCFs in 1 job.\n",
      "2022-02-07 02:29:39 Hail: INFO: Starting phase 1/1, job 1/1 to create 1 merged file, corresponding to ~100.0% of total I/O.\n",
      "2022-02-07 02:34:45 Hail: INFO: wrote matrix table with 0 rows and 100 columns in 2592 partitions to file:///directflow/ClinicalGenomicsPipeline/dev/2021-02-04-PIPELINE-1885-All-Hail/EricData/100_samples_GRCh37_2.mt\n",
      "    Total size: 51.02 KiB\n",
      "    * Rows/entries: 50.63 KiB\n",
      "    * Columns: 396.00 B\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 0 rows (20.00 B)\n",
      "    * Largest partition:  0 rows (20.00 B)\n",
      "2022-02-07 02:34:45 Hail: INFO: Finished phase 1/1, job 1/1, 100% of total I/O finished.\n",
      "2022-02-07 02:34:45 Hail: INFO: Finished phase 1/1.\n",
      "2022-02-07 02:34:45 Hail: INFO: Finished!\n"
     ]
    }
   ],
   "source": [
    "# Run jointcaller\n",
    "hl.experimental.run_combiner(inputs, out_file=output_file, tmp_path=temp_bucket, reference_genome='GRCh37', key_by_locus_and_alleles=True,use_genome_default_intervals=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d264b5-bbfb-4ecc-a53b-d21ee2d9a322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
